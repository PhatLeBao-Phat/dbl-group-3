{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54d4fb78",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_polarity' from 'Tools.sentiment_analysis' (C:\\Users\\PC\\Documents\\Tue course\\DBL\\dbl-group-3\\Tools\\sentiment_analysis.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-9afd60c09f13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mTools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentiment_analysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mextract_sentiment_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mTools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentiment_analysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_polarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_polarity' from 'Tools.sentiment_analysis' (C:\\Users\\PC\\Documents\\Tue course\\DBL\\dbl-group-3\\Tools\\sentiment_analysis.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sys \n",
    "from pathlib import Path \n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from Tools.sentiment_analysis import extract_sentiment_score\n",
    "from Tools.sentiment_analysis import get_label, get_polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a69e4b4",
   "metadata": {},
   "source": [
    "## Evaluation Roberta model and Textblob model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fe1d59",
   "metadata": {},
   "source": [
    "### 1. load the external data from Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b66589",
   "metadata": {},
   "source": [
    "#### About this file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de737681",
   "metadata": {},
   "source": [
    "This is the sentiment140 dataset.\n",
    "It contains 1,600,000 tweets extracted using the twitter api . The tweets have been annotated (0 = negative, 2 = neutral, 4 = positive) and they can be used to detect sentiment .\n",
    "It contains the following 6 fields:\n",
    "\n",
    "target: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "ids: The id of the tweet ( 2087)\n",
    "date: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "flag: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "user: the user that tweeted (robotickilldozr)\n",
    "text: the text of the tweet (Lyx is cool)\n",
    "The official link regarding the dataset with resources about how it was generated is here\n",
    "The official paper detailing the approach is here\n",
    "\n",
    "According to the creators of the dataset:\n",
    "\n",
    "\"Our approach was unique because our training data was automatically created, as opposed to having humans manual annotate tweets. In our approach, we assume that any tweet with positive emoticons, like :), were positive, and tweets with negative emoticons, like :(, were negative. We used the Twitter Search API to collect these tweets by using keyword search\"\n",
    "\n",
    "citation: Go, A., Bhayani, R. and Huang, L., 2009. Twitter sentiment classification using distant supervision. CS224N Project Report, Stanford, 1(2009), p.12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c6dbb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_k = pd.read_csv('../../csv_files/kaggle_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40a2c564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text     label\n",
       "0       0  is upset that he can't update his Facebook by ...  Negative\n",
       "1       0  @Kenichan I dived many times for the ball. Man...  Negative\n",
       "2       0    my whole body feels itchy and like its on fire   Negative\n",
       "3       0  @nationwideclass no, it's not behaving at all....  Negative\n",
       "4       0                      @Kwesidei not the whole crew   Negative"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify to form with attribute label and text \n",
    "df_k = df_k[df_k.columns[[0, -1]]]\n",
    "df_k.columns = ['target', 'text']\n",
    "df_k['label'] = df_k['target'].map({0 : 'Negative', 2 : 'Neutral', 4 : 'Positive'})\n",
    "df_k.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f044400",
   "metadata": {},
   "source": [
    "### 2. Load the external data from SemEval-2017 Task 4: Sentiment Analysis in Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f097cc",
   "metadata": {},
   "source": [
    "#### About the paper "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb49cd4",
   "metadata": {},
   "source": [
    "This paper describes the fifth year of the Sentiment Analysis in Twitter task. SemEval-2017 Task 4 continues with a rerun of the subtasks of SemEval-2016 Task 4, which include identifying the overall sentiment of the tweet, sentiment towards a topic with classification on a two-point and on a five-point ordinal scale, and quantification of the distribution of sentiment towards a topic across a number of tweets: again on a two-point and on a five-point ordinal scale. Compared to 2016, we made two changes: (i) we introduced a new language, Arabic, for all subtasks, and (ii) we made available information from the profiles of the Twitter users who posted the target tweets. The task continues to be very popular, with a total of 48 teams participating this year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae28c8ec",
   "metadata": {},
   "source": [
    "https://alt.qcri.org/semeval2017/task4/index.php?id=papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9603fc",
   "metadata": {},
   "source": [
    "#### About the file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b140d354",
   "metadata": {},
   "source": [
    "link download full data: https://alt.qcri.org/semeval2017/task4/?id=download-the-full-training-data-for-semeval-2017-task-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c165860",
   "metadata": {},
   "source": [
    "Subtask A: Message Polarity Classification.\n",
    "Given a message, classify whether the message is of positive, negative, or neutral sentiment.\n",
    "The training set are manually annotated "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f641651f",
   "metadata": {},
   "source": [
    "We only use the data of 2016-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "675ed0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>628949369883000832</th>\n",
       "      <th>negative</th>\n",
       "      <th>dear @Microsoft the newOoffice for Mac is great and all, but no Lync update? C'mon.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628976607420645377</td>\n",
       "      <td>negative</td>\n",
       "      <td>@Microsoft how about you make a system that do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>629023169169518592</td>\n",
       "      <td>negative</td>\n",
       "      <td>I may be ignorant on this issue but... should ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>629179223232479232</td>\n",
       "      <td>negative</td>\n",
       "      <td>Thanks to @microsoft, I just may be switching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>629186282179153920</td>\n",
       "      <td>neutral</td>\n",
       "      <td>If I make a game as a #windows10 Universal App...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629226490152914944</td>\n",
       "      <td>positive</td>\n",
       "      <td>Microsoft, I may not prefer your gaming branch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   628949369883000832  negative  \\\n",
       "0  628976607420645377  negative   \n",
       "1  629023169169518592  negative   \n",
       "2  629179223232479232  negative   \n",
       "3  629186282179153920   neutral   \n",
       "4  629226490152914944  positive   \n",
       "\n",
       "  dear @Microsoft the newOoffice for Mac is great and all, but no Lync update? C'mon.  \n",
       "0  @Microsoft how about you make a system that do...                                   \n",
       "1  I may be ignorant on this issue but... should ...                                   \n",
       "2  Thanks to @microsoft, I just may be switching ...                                   \n",
       "3  If I make a game as a #windows10 Universal App...                                   \n",
       "4  Microsoft, I may not prefer your gaming branch...                                   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('../../csv_files/twitter-2016train-A.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42cac53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = ['id', 'topic', 'label', 'text']\n",
    "df.columns = ['id', 'label', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b97c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='id', inplace=True)\n",
    "df['label'] = df['label'].map({'negative' : 'Negative', 'positive' : 'Positive', 'neutral' : 'Neutral'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74720360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'] = df['label'].map({'Negative' : -1, 'Positive' : 1, 'Neutral' : 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915236d2",
   "metadata": {},
   "source": [
    "### 3. Evaluation Roberta model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "359265b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.664, 0.8709007659007659)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_check(n_check, n_samp, df):\n",
    "    \"\"\"\n",
    "    do n_check loop on n_samp random observations from the df. get the prediction accuracy for each loop\n",
    "    then get average over all loop\n",
    "    \"\"\"\n",
    "    lst = []\n",
    "    lst_TF = []\n",
    "    count = 0\n",
    "    for _ in range(n_check):\n",
    "        df_light = df.sample(n=n_samp)\n",
    "        lst_label = []\n",
    "        lst_score = []\n",
    "        for text in df_light['text']:  # loop through each row to get the prediction label and prediction score \n",
    "            count += 1\n",
    "            if count%100 == 0:\n",
    "                print(count)\n",
    "            tup = extract_sentiment_score(text)\n",
    "            lst_label.append(tup[0])\n",
    "            lst_score.append(tup[1])\n",
    "        df_light['prediction'] = lst_label\n",
    "        df_light['sentiment_score'] = lst_score\n",
    "        lst.append(sum(df_light['label'] == df_light['prediction'])/len(df_light))\n",
    "        \n",
    "        # Calculate TP/(TP + FP)\n",
    "        df_light = df_light[df_light.prediction=='Positive'] \n",
    "        lst_TF.append(sum(df_light['label'] == df_light['prediction'])/len(df_light))\n",
    "    return sum(lst)/len(lst), sum(lst_TF)/len(lst_TF)\n",
    "random_check(n_check=5, n_samp=100, df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f66060b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3246574323719318"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_check_for_numeric(n_check, n_samp, df):\n",
    "    \"\"\"\n",
    "    do n_check loop on n_samp random observations from the df. get the prediction accuracy for each loop\n",
    "    then get average over all loop\n",
    "    \"\"\"\n",
    "    lst = []\n",
    "    lst_TF = []\n",
    "    count = 0\n",
    "    for _ in range(n_check):\n",
    "        df_light = df.sample(n=n_samp)\n",
    "        lst_label = []\n",
    "        lst_score = []\n",
    "        for text in df_light['text']:  # loop through each row to get the prediction label and prediction score \n",
    "            count += 1\n",
    "            if count%100 == 0:\n",
    "                print(count)\n",
    "            tup = extract_sentiment_score(text)\n",
    "            lst_label.append(tup[0])\n",
    "            lst_score.append(tup[1])\n",
    "        df_light['prediction'] = lst_label\n",
    "        df_light['sentiment_score'] = lst_score\n",
    "        a = (df_light['sentiment_score'] - df_light['score'])**2\n",
    "        lst.append(sum(a)/len(a))\n",
    "    return sum(lst)/len(lst)\n",
    "random_check_for_numeric(n_check=5, n_samp=100, df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82510b0",
   "metadata": {},
   "source": [
    "### 4. Evaluation Textblob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6679a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4650000000000001, 0.6088379640446522)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_check_tb(n_check, n_samp, df):\n",
    "    \"\"\"\n",
    "    But for Textblob\n",
    "    \"\"\"\n",
    "    lst = []\n",
    "    lst_TF = []\n",
    "    count = 0\n",
    "    for _ in range(n_check):\n",
    "        df_light = df.sample(n=n_samp)\n",
    "        df_light['prediction'] = df_light['text'].apply(get_label)\n",
    "        lst.append(sum(df_light['label'] == df_light['prediction'])/len(df_light))\n",
    "        \n",
    "        # Calculate TP/(TP + FP)\n",
    "        df_light = df_light[df_light.prediction=='Positive'] \n",
    "        lst_TF.append(sum(df_light['label'] == df_light['prediction'])/len(df_light))\n",
    "    return sum(lst)/len(lst), sum(lst_TF)/len(lst_TF)\n",
    "random_check_tb(n_check=100, n_samp=100, df=df)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
